# Projeto de TCC: Redes Neurais com Snake Game

Este projeto implementa uma InteligÃªncia Artificial capaz de aprender a jogar o clÃ¡ssico jogo da cobrinha (Snake) utilizando Aprendizado por ReforÃ§o (Deep Q-Learning).

## ğŸ“‹ Funcionalidades
- **Rede Neural (Deep Q-Network)**: Aprende estratÃ©gias para maximizar a pontuaÃ§Ã£o.
- **Sistema de Energia**: A cobra gasta energia ao se mover e recupera ao comer. Isso incentiva a IA a ser eficiente.
- **Dashboard em Tempo Real**:
  - Score Atual e Recorde (Melhor Cobra).
  - Barra de Energia Visual.
  - GrÃ¡fico de evoluÃ§Ã£o do aprendizado.

## ğŸ› ï¸ Tecnologias Utilizadas
- **Python 3.10+**
- **PyTorch**: ConstruÃ§Ã£o e treinamento da Rede Neural.
- **Pygame**: Interface grÃ¡fica e ambiente do jogo.
- **NumPy**: ManipulaÃ§Ã£o matemÃ¡tica.
- **Matplotlib**: Plotagem de grÃ¡ficos de performance.

## ğŸš€ Como Executar

1. **Instale as dependÃªncias**:
   Abra o terminal na pasta do projeto e execute:
   ```bash
   pip install -r requirements.txt
   ```

2. **Execute o treinamento**:
   ```bash
   python agent.py
   ```

A janela do jogo abrirÃ¡ e vocÃª verÃ¡ a IA aprendendo (errando muito no inÃ­cio e melhorando com o tempo). Um grÃ¡fico tambÃ©m serÃ¡ exibido mostrando a evoluÃ§Ã£o da pontuaÃ§Ã£o mÃ©dia.

## ğŸ“‚ Estrutura dos Arquivos
- `agent.py`: O cÃ©rebro da IA. ContÃ©m o loop de treinamento e a tomada de decisÃ£o.
- `game.py`: O ambiente do jogo. LÃ³gica da cobra, colisÃµes e renderizaÃ§Ã£o.
- `model.py`: A arquitetura da Rede Neural (Linear Q-Net).
- `helper.py`: UtilitÃ¡rios para visualizaÃ§Ã£o de dados (grÃ¡ficos).

---
**Nota**: O cÃ³digo estÃ¡ comentado detalhadamente para fins didÃ¡ticos.
